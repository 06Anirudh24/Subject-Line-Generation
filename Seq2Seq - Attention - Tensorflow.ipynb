{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Input, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.activations import softmax\n",
    "from keras.layers.core import Dense, Activation, RepeatVector, Permute\n",
    "from keras.layers import Input, Embedding, Multiply, Concatenate, Lambda\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subject:\n",
    "    \n",
    "    kid = 0    \n",
    "    def __init__(self, *args):\n",
    "        self.id = Subject.kid\n",
    "        Subject.kid+=1\n",
    "        self.subject = None\n",
    "        self.targets = None\n",
    "        if len(args)==1:\n",
    "            self.subject = args[0]\n",
    "            self.targets = []        \n",
    "        elif len(args)==2:\n",
    "            self.subject = args[0]\n",
    "            if isinstance(args[1], str):\n",
    "                self.targets = [args[1]]\n",
    "            else:\n",
    "                self.targets = args[1]\n",
    "    \n",
    "    def getID(self):\n",
    "        '''Returns subject id'''\n",
    "        return self.id\n",
    "    \n",
    "    def getData(self):\n",
    "        '''Returns subject id, original and target subject lines'''\n",
    "        return self.id, self.subject, self.targets\n",
    "    \n",
    "    def getOrigSubject(self):\n",
    "        '''Returns subject line'''\n",
    "        return self.subject\n",
    "    \n",
    "    def setOrigSubject(self, s):\n",
    "        '''Takes a new subject as input and updates the local variable'''\n",
    "        self.subject = s\n",
    "    \n",
    "    def getTargetSubjects(self):\n",
    "        '''Returns target subject lines'''\n",
    "        return self.targets\n",
    "    \n",
    "    def addTargetSubjects(self, s):\n",
    "        '''Args: List of target subjects. Adds to target subject lines.'''\n",
    "        self.targets.extend(s)\n",
    "\n",
    "class SubjectLines:\n",
    "    def __init__(self, *args):\n",
    "        self.subxID = dict()\n",
    "        self.IDxsub = dict()\n",
    "        if len(args)==1:\n",
    "            self.addSubjects(args[0])   \n",
    "        elif len(args)==2:\n",
    "            self.addSubTargets(args[0], args[1]) \n",
    "    \n",
    "    def getStats(self):\n",
    "        '''Returns number of subject lines'''\n",
    "        return len(list(self.IDxsub))\n",
    "    \n",
    "    def getSubject(self, *args):\n",
    "        '''Returns object instance of Subject class with the given subject id.'''\n",
    "        if isinstance(args[0], int):\n",
    "            return self.IDxsub[args[0]]\n",
    "        else:\n",
    "            return self.subxID[args[0]]\n",
    "    \n",
    "    def getID(self, sub):\n",
    "        '''Returns id of the given subject.'''\n",
    "        if sub in self.subxID.keys():\n",
    "            return self.subxID[sub]\n",
    "        else:\n",
    "            print(\"Not Found\")\n",
    "    \n",
    "    def addSubjects(self, subjects):\n",
    "        '''Adds the input subject lines to the class instance variable'''\n",
    "        for sub in subjects:\n",
    "            s = Subject(sub)\n",
    "            self.IDxsub[s.getID()] = s \n",
    "            self.subxID[sub] = s.getID()\n",
    "    \n",
    "    def addSubTargets(self, subjects, targets):\n",
    "        '''Adds subjects and their targets'''\n",
    "        for sub, tar in zip(subjects, targets):\n",
    "            s = Subject(sub, tar)\n",
    "            self.IDxsub[s.getID()] = s \n",
    "            self.subxID[sub] = s.getID()\n",
    "    \n",
    "    def addTarget(self, *args):\n",
    "        '''\n",
    "        Args (Multiple Options):\n",
    "        1. (id, target)\n",
    "        2. (id, targets)\n",
    "        3. (sub, target)\n",
    "        4. (sub, targets)\n",
    "        '''\n",
    "        s=None\n",
    "        if isinstance(args[0], int):\n",
    "            s = self.IDxsub[args[0]]\n",
    "        else:\n",
    "            s = self.subxID[args[0]]\n",
    "        if isinstance(args[1], str):\n",
    "            s.addTargetSubjects([args[1]])\n",
    "        else:            \n",
    "            s.addTargetSubjects(args[1])\n",
    "    \n",
    "    def getAllSubjects(self):\n",
    "        '''Returns a dictionary of all subjects, with key as subject id and value as the corresponding subject line'''\n",
    "        return self.IDxsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectsDataset:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = None\n",
    "\n",
    "    def unicode_to_ascii(self, s):\n",
    "        return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    ## Step 1 and Step 2 \n",
    "    def preprocess_sentence(self, w):\n",
    "        w = self.unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "        # creating a space between a word and the punctuation following it\n",
    "        # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "        # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "        w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "        w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "        # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "        w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "        w = w.strip()\n",
    "\n",
    "        # adding a start and an end token to the sentence\n",
    "        # so that the model know when to start and stop predicting.\n",
    "        w = '<start> ' + w + ' <end>'\n",
    "        return w\n",
    "\n",
    "    def create_dataset(self, path, num_examples):\n",
    "        # path : path to spa-eng.txt file\n",
    "        # num_examples : Limit the total number of training example for faster training (set num_examples = len(lines) to use full data)\n",
    "        data = pickle.load(open(path, \"rb\" ))\n",
    "        subs = data.getAllSubjects()\n",
    "        word_pairs = [[self.preprocess_sentence(sub.getOrigSubject()), self.preprocess_sentence(sub.getTargetSubjects()[0])]  for i, sub in subs.items() if i<num_examples]\n",
    "        return zip(*word_pairs)\n",
    "\n",
    "    # Step 3 and Step 4\n",
    "    def tokenize(self, encoder_text, decoder_text):\n",
    "        \n",
    "        print(len(encoder_text), \"Encoder Subject line example: {}\".format(encoder_text[0]))\n",
    "        print(len(decoder_text), \"Decoder Subject line example: {}\".format(decoder_text[0]))\n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>')\n",
    "        tokenizer.fit_on_texts(encoder_text)\n",
    "        tokenizer.fit_on_texts(decoder_text)\n",
    "\n",
    "        ## tf.keras.preprocessing.text.Tokenizer.texts_to_sequences converts string (w1, w2, w3, ......, wn) \n",
    "        ## to a list of correspoding integer ids of words (id_w1, id_w2, id_w3, ...., id_wn)\n",
    "        encoder_sequences = tokenizer.texts_to_sequences(encoder_text)\n",
    "        decoder_sequences = tokenizer.texts_to_sequences(decoder_text)\n",
    "\n",
    "        ## tf.keras.preprocessing.sequence.pad_sequences takes argument a list of integer id sequences \n",
    "        ## and pads the sequences to match the longest sequences in the given input\n",
    "        padded_encoder_seq = tf.keras.preprocessing.sequence.pad_sequences(encoder_sequences, padding='post')\n",
    "        padded_decoder_seq = tf.keras.preprocessing.sequence.pad_sequences(decoder_sequences, padding='post')\n",
    "        \n",
    "        return padded_encoder_seq, padded_decoder_seq, tokenizer\n",
    "\n",
    "    def load_dataset(self, path, num_examples=None):\n",
    "        # creating cleaned input, output pairs\n",
    "        inp, tar = self.create_dataset(path, num_examples)\n",
    "        input_encoder_tensor, input_decoder_tensor, tokenizer = self.tokenize(inp, tar)\n",
    "\n",
    "        return input_encoder_tensor, input_decoder_tensor, tokenizer\n",
    "\n",
    "    def call(self, file_path, num_examples, BUFFER_SIZE, BATCH_SIZE):\n",
    "        input_tensor, target_tensor, self.tokenizer = self.load_dataset(file_path, num_examples)\n",
    "\n",
    "        input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n",
    "        train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n",
    "        val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "        return train_dataset, val_dataset, self.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Encoder Subject line example: <start> open asap ! you re receiving your daily dose of deals . you will this we just know it <end>\n",
      "1000 Decoder Subject line example: <start> we are working on it right now ! . ! ! ! you ll be a customer at one of <end>\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 32000\n",
    "BATCH_SIZE = 64\n",
    "num_examples = 1000\n",
    "path = 'data/Client15.p'\n",
    "\n",
    "dataset_creator = SubjectsDataset()\n",
    "train_dataset, val_dataset, sub_tokenizer = dataset_creator.call(path, num_examples, BUFFER_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 25]), TensorShape([64, 107]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(sub_tokenizer.word_index)+1\n",
    "max_length_input = example_input_batch.shape[1]\n",
    "max_length_output = example_target_batch.shape[1]\n",
    "\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "steps_per_epoch = num_examples//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4311, 25, 107)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, max_length_input, max_length_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        ##-------- LSTM layer in Encoder ------- ##\n",
    "        self.lstm_layer = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, h, c = self.lstm_layer(x, initial_state = hidden)\n",
    "        return output, h, c\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return [tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 25, 1024)\n",
      "Encoder h vecotr shape: (batch size, units) (64, 1024)\n",
      "Encoder c vector shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder h vecotr shape: (batch size, units) {}'.format(sample_h.shape))\n",
    "print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_type='luong'):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.attention_type = attention_type\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        #Final Dense layer on which softmax will be applied\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # Define the fundamental cell for decoder recurrent structure\n",
    "        self.decoder_rnn_cell = tf.keras.layers.LSTMCell(self.dec_units)\n",
    "        \n",
    "        # Sampler\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "        # Create attention mechanism with memory = None\n",
    "        self.attention_mechanism = self.build_attention_mechanism(self.dec_units, \n",
    "                                                              None, self.batch_sz*[max_length_input], self.attention_type)\n",
    "        \n",
    "        # Wrap attention mechanism with the fundamental rnn cell of decoder\n",
    "        self.rnn_cell = self.build_rnn_cell(batch_sz)\n",
    "\n",
    "        # Define the decoder with respect to fundamental rnn cell\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n",
    "\n",
    "    def build_rnn_cell(self, batch_sz):\n",
    "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell, \n",
    "                                  self.attention_mechanism, attention_layer_size=self.dec_units)\n",
    "        return rnn_cell\n",
    "\n",
    "    def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n",
    "        # ------------- #\n",
    "        # typ: Which sort of attention (Bahdanau, Luong)\n",
    "        # dec_units: final dimension of attention outputs \n",
    "        # memory: encoder hidden states of shape (batch_size, max_length_input, enc_units)\n",
    "        # memory_sequence_length: 1d array of shape (batch_size) with every element set to max_length_input (for masking purpose)\n",
    "\n",
    "        if(attention_type=='bahdanau'):\n",
    "            return tfa.seq2seq.BahdanauAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
    "        else:\n",
    "            return tfa.seq2seq.LuongAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
    "\n",
    "    def build_initial_state(self, batch_sz, encoder_state, Dtype):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=batch_sz, dtype=Dtype)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
    "        return decoder_initial_state\n",
    "\n",
    "    def call(self, inputs, initial_state):\n",
    "        x = self.embedding(inputs)\n",
    "        outputs, _, _ = self.decoder(x, initial_state=initial_state, sequence_length=self.batch_sz*[max_length_output-1])\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Outputs Shape:  (64, 106, 4311)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size, embedding_dim, units, BATCH_SIZE, 'luong')\n",
    "sample_x = tf.random.uniform((BATCH_SIZE, max_length_output))\n",
    "decoder.attention_mechanism.setup_memory(sample_output)\n",
    "initial_state = decoder.build_initial_state(BATCH_SIZE, [sample_h, sample_c], tf.float32)\n",
    "\n",
    "\n",
    "sample_decoder_outputs = decoder(sample_x, initial_state)\n",
    "\n",
    "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # real shape = (BATCH_SIZE, max_length_output)\n",
    "    # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
    "    cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = cross_entropy(y_true=real, y_pred=pred)\n",
    "    mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)  \n",
    "    loss = mask* loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
    "\n",
    "\n",
    "        dec_input = targ[ : , :-1 ] # Ignore <end> token\n",
    "        real = targ[ : , 1: ]         # ignore <start> token\n",
    "\n",
    "        # Set the AttentionMechanism object with encoder_outputs\n",
    "        decoder.attention_mechanism.setup_memory(enc_output)\n",
    "\n",
    "        # Create AttentionWrapperState as initial_state for decoder\n",
    "        decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
    "        pred = decoder(dec_input, decoder_initial_state)\n",
    "        logits = pred.rnn_output\n",
    "        print(logits)\n",
    "        loss = loss_function(real, logits)\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"decoder_2/basic_decoder_4/decoder/transpose_1:0\", shape=(64, None, 4311), dtype=float32)\n",
      "Tensor(\"decoder_2/basic_decoder_4/decoder/transpose_1:0\", shape=(64, None, 4311), dtype=float32)\n",
      "Epoch 1 Batch 0 Loss 1.3446\n",
      "Epoch 1 Loss 1.0138\n",
      "Time taken for 1 epoch 32.24345684051514 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.1667\n",
      "Epoch 2 Loss 0.8869\n",
      "Time taken for 1 epoch 29.452654123306274 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.1025\n",
      "Epoch 3 Loss 0.8607\n",
      "Time taken for 1 epoch 29.591081142425537 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.0714\n",
      "Epoch 4 Loss 0.8544\n",
      "Time taken for 1 epoch 29.45012092590332 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "EPOCHS = 4\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    # print(enc_hidden[0].shape, enc_hidden[1].shape)\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 25 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                       batch,\n",
    "                                                       batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "#     if (epoch + 1) % 2 == 0:\n",
    "#         checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_subject(sentence):\n",
    "    sentence = dataset_creator.preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [sub_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                          maxlen=max_length_input,\n",
    "                                                          padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    inference_batch_size = inputs.shape[0]\n",
    "    result = ''\n",
    "\n",
    "    enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
    "    enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
    "\n",
    "    dec_h = enc_h\n",
    "    dec_c = enc_c\n",
    "\n",
    "    start_tokens = tf.fill([inference_batch_size], sub_tokenizer.word_index['<start>'])\n",
    "    end_token = sub_tokenizer.word_index['<end>']\n",
    "\n",
    "    greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
    "\n",
    "    # Instantiate BasicDecoder object\n",
    "    decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder.rnn_cell, sampler=greedy_sampler, output_layer=decoder.fc)\n",
    "    # Setup Memory in decoder stack\n",
    "    decoder.attention_mechanism.setup_memory(enc_out)\n",
    "\n",
    "    # set decoder_initial_state\n",
    "    decoder_initial_state = decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)\n",
    "\n",
    "\n",
    "    ### Since the BasicDecoder wraps around Decoder's rnn cell only, you have to ensure that the inputs to BasicDecoder \n",
    "    ### decoding step is output of embedding layer. tfa.seq2seq.GreedyEmbeddingSampler() takes care of this. \n",
    "    ### You only need to get the weights of embedding layer, which can be done by decoder.embedding.variables[0] and pass this callabble to BasicDecoder's call() function\n",
    "\n",
    "    decoder_embedding_matrix = decoder.embedding.variables[0]\n",
    "\n",
    "    outputs, _, _ = decoder_instance(decoder_embedding_matrix, start_tokens = start_tokens, end_token= end_token, initial_state=decoder_initial_state)\n",
    "    return outputs.sample_id.numpy()\n",
    "\n",
    "def predict_sub(sentence):\n",
    "    result = evaluate_subject(sentence)\n",
    "    print(result)\n",
    "    result = sub_tokenizer.sequences_to_texts(result)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted Subject: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 4 4 4 4 4 4 4 4 4 3]]\n",
      "Input: join us for a conversation is a recovery in sight ? lessons from around the world.\n",
      "Predicted Subject: ['! . . . . . . . . . <end>']\n"
     ]
    }
   ],
   "source": [
    "predict_sub(u'join us for a conversation is a recovery in sight ? lessons from around the world.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pavan_bits_DS",
   "language": "python",
   "name": "pavan_bits_ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
